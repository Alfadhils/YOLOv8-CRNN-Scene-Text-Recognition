{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import cv2\n",
    "import time\n",
    "from crnn_dataset import TRDataset\n",
    "from crnn_model import CRNN\n",
    "from crnn_decoder import ctc_decode\n",
    "from crnn_predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def STR(img_path, yolo_weight, crnn_config):\n",
    "    start = time.time()\n",
    "    model = YOLO(yolo_weight)\n",
    "    \n",
    "    if type(img_path) is str:\n",
    "        org_img = Image.open(img_path)\n",
    "    else :\n",
    "        org_img = img_path\n",
    "\n",
    "    results = model(org_img, conf=0.4, verbose=False)\n",
    "    \n",
    "    cropped_texts = []\n",
    "    for r in results:\n",
    "        for text in r.boxes.xywh:\n",
    "            x,y,w,h = text.cpu().numpy()\n",
    "            cropped_img = org_img.crop((x-w/2, y-w/2, x + w/2, y + h/2))\n",
    "            cropped_texts.append(cropped_img)\n",
    "            \n",
    "    config = torch.load(crnn_config)\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    if cropped_texts:\n",
    "        detect_dataset = TRDataset(images=cropped_texts, img_height=config['img_height'], img_width=config['img_width'])\n",
    "        detect_loader = torch.utils.data.DataLoader(detect_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "        num_class = len(TRDataset.LABEL2CHAR) + 1\n",
    "\n",
    "        crnn = CRNN(1, config['img_height'], config['img_width'], num_class,\n",
    "                        map_to_seq=config['map_to_seq'],\n",
    "                        rnn_hidden=config['rnn_hidden'])\n",
    "\n",
    "        if config['state_dict']:\n",
    "            crnn.load_state_dict(config['state_dict'])\n",
    "\n",
    "        crnn.to(device)\n",
    "\n",
    "        texts = predict(crnn, detect_loader, label2char=TRDataset.LABEL2CHAR)\n",
    "    else :\n",
    "        print('No text detected')\n",
    "        return org_img\n",
    "\n",
    "    image_draw = org_img.copy()\n",
    "    draw = ImageDraw.Draw(image_draw)\n",
    "\n",
    "    font = ImageFont.truetype(\"arialbd.ttf\", size=16)\n",
    "\n",
    "    for r in results:\n",
    "        for (x,y,w,h),text in zip(r.boxes.xywh.cpu().numpy(),texts):\n",
    "            draw.rectangle([int(x-w/2), int(y-h/2), int(x+w/2), int(y+h/2)], outline=\"red\", width=2)\n",
    "\n",
    "            draw.text((int(x-w/2), int(y-h/2-18)), text, fill=\"red\", font=font)\n",
    "            \n",
    "    end = time.time()\n",
    "    print(f\"Total time : {end-start}, Detected {len(cropped_texts)} texts\")\n",
    "    return image_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '../demo/TD.jpg'\n",
    "yolo_weight = '../checkpoints/yolov8_5k.pt'\n",
    "crnn_config = '../checkpoints/crnn_s100k.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = STR(img_path, yolo_weight, crnn_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../demo/street.mp4')\n",
    "\n",
    "# Get video properties\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can choose the codec based on your needs\n",
    "output_video = cv2.VideoWriter('street_result.avi', fourcc, fps, (width, height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        results_pil = STR(frame_pil, yolo_weight, crnn_config)\n",
    "        \n",
    "        results_cv2 = cv2.cvtColor(np.array(results_pil), cv2.COLOR_RGB2BGR)\n",
    "        end = time.perf_counter()\n",
    "        \n",
    "        total_time = end - start\n",
    "        fps = 1 / total_time\n",
    "        \n",
    "        cv2.putText(results_cv2, f\"FPS: {int(fps)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.imshow(\"YOLOv8 Inference\", results_cv2)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        output_video.write(results_cv2)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or not ret:\n",
    "        break\n",
    "\n",
    "# Release the VideoWriter and VideoCapture objects\n",
    "cap.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your_env_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
